{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "474dbed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b717c56f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def leave_one_out_split(outfit_ids, groups, derived_booking_times_start,derived_booking_times_end):\n",
    "    \"\"\"\n",
    "    Splits the data into training and test sets by leaving out the last entry based on booking times.\n",
    "\n",
    "    Parameters:\n",
    "    outfit_ids (list): List of outfit IDs.\n",
    "    groups (list): List of group IDs corresponding to the outfits.\n",
    "    derived_booking_times (list): List of booking times.\n",
    "\n",
    "    Returns:\n",
    "    tuple: Training and test sets for outfit IDs, groups, and booking times.\n",
    "    \"\"\"\n",
    "    outfit_ids, groups, derived_booking_times_start,derived_booking_times_end = np.array(outfit_ids), np.array(groups), np.array(derived_booking_times_start),np.array(derived_booking_times_end)\n",
    "    sorted_indices = np.argsort(derived_booking_times_start)\n",
    "    return(\n",
    "    outfit_ids[sorted_indices[:-num_to_leave]], outfit_ids[sorted_indices[-num_to_leave:]], \n",
    "        groups[sorted_indices[:-num_to_leave]], groups[sorted_indices[-num_to_leave:]], \n",
    "        derived_booking_times_start[sorted_indices[:-num_to_leave]], derived_booking_times_start[sorted_indices[-num_to_leave:]], \n",
    "        derived_booking_times_end[sorted_indices[:-num_to_leave]], derived_booking_times_end[sorted_indices[-num_to_leave:]]\n",
    "\n",
    "    )\n",
    "def leave_one_out_split_unique(outfit_ids, groups, derived_booking_times_start,derived_booking_times_end):\n",
    "    \"\"\"\n",
    "    Splits the data into training and test sets by leaving out the last unique group entry based on booking times.\n",
    "\n",
    "    Parameters:\n",
    "    outfit_ids (list): List of outfit IDs.\n",
    "    groups (list): List of group IDs corresponding to the outfits.\n",
    "    derived_booking_times (list): List of booking times.\n",
    "\n",
    "    Returns:\n",
    "    tuple: Training and test sets for outfit IDs, groups, and booking times, or None if no unique group is found.\n",
    "    \"\"\"\n",
    "    outfit_ids, groups, derived_booking_times_start,derived_booking_times_end = np.array(outfit_ids), np.array(groups), np.array(derived_booking_times_start),np.array(derived_booking_times_end)\n",
    "    \n",
    "    sorted_indices = np.argsort(derived_booking_times_start)\n",
    "    sorted_outfit_ids = outfit_ids[sorted_indices]\n",
    "    sorted_groups = groups[sorted_indices]\n",
    "    derived_booking_times_start = derived_booking_times_start[sorted_indices]\n",
    "    derived_booking_times_end=derived_booking_times_end[sorted_indices]\n",
    "    \n",
    "    unique_groups, counts = np.unique(sorted_groups, return_counts=True)\n",
    "    \n",
    "    single_count_indices = np.where(counts == 1)[0]\n",
    "    if len(single_count_indices) == 0:\n",
    "        print(f\"No unique outfit found with groups {groups}\")\n",
    "        return None\n",
    "    \n",
    "    unique_group = unique_groups[single_count_indices[0]]\n",
    "    unique_group_index = np.where(sorted_groups == unique_group)[0][0]\n",
    "    remaining_indices = np.arange(len(sorted_groups)) != unique_group_index\n",
    "    \n",
    "    return (\n",
    "        outfit_ids[sorted_indices[:-num_to_leave]], outfit_ids[sorted_indices[-num_to_leave:]], \n",
    "        groups[sorted_indices[:-num_to_leave]], groups[sorted_indices[-num_to_leave:]], \n",
    "        derived_booking_times_start[sorted_indices[:-num_to_leave]], derived_booking_times_start[sorted_indices[-num_to_leave:]], \n",
    "        derived_booking_times_end[sorted_indices[:-num_to_leave]], derived_booking_times_end[sorted_indices[-num_to_leave:]]\n",
    "\n",
    "    )\n",
    "\n",
    "def leave_percentage_out_split(outfit_ids, groups, derived_booking_times_start,derived_booking_times_end, percentage=0.2):\n",
    "    \"\"\"\n",
    "    Splits the data into training and test sets by leaving out a percentage of the entries based on booking times.\n",
    "\n",
    "    Parameters:\n",
    "    outfit_ids (list): List of outfit IDs.\n",
    "    groups (list): List of group IDs corresponding to the outfits.\n",
    "    derived_booking_times (list): List of booking times.\n",
    "    percentage (float): Percentage of data to leave out for the test set.\n",
    "\n",
    "    Returns:\n",
    "    tuple: Training and test sets for outfit IDs, groups, and booking times.\n",
    "    \"\"\"\n",
    "    outfit_ids, groups, derived_booking_times_start,derived_booking_times_end = np.array(outfit_ids), np.array(groups), np.array(derived_booking_times_start),np.array(derived_booking_times_end)\n",
    "    num_to_leave = max(math.floor(len(outfit_ids) * percentage), 1)\n",
    "\n",
    "    sorted_indices = np.argsort(derived_booking_times_start)\n",
    "    return (\n",
    "    outfit_ids[sorted_indices[:-num_to_leave]], outfit_ids[sorted_indices[-num_to_leave:]], \n",
    "        groups[sorted_indices[:-num_to_leave]], groups[sorted_indices[-num_to_leave:]], \n",
    "        derived_booking_times_start[sorted_indices[:-num_to_leave]], derived_booking_times_start[sorted_indices[-num_to_leave:]], \n",
    "        derived_booking_times_end[sorted_indices[:-num_to_leave]], derived_booking_times_end[sorted_indices[-num_to_leave:]]\n",
    "\n",
    "    )\n",
    "\n",
    "def leave_percentage_out_split_unique(outfit_ids, groups, derived_booking_times_start,derived_booking_times_end, percentage=0.2):\n",
    "    \"\"\"\n",
    "    Splits the data into training and test sets by leaving out a percentage of unique group entries based on booking times.\n",
    "\n",
    "    Parameters:\n",
    "    outfit_ids (list): List of outfit IDs.\n",
    "    groups (list): List of group IDs corresponding to the outfits.\n",
    "    derived_booking_times (list): List of booking times.\n",
    "    percentage (float): Percentage of data to leave out for the test set.\n",
    "\n",
    "    Returns:\n",
    "    tuple: Training and test sets for outfit IDs, groups, and booking times, or None if no unique group is found.\n",
    "    \"\"\"\n",
    "    outfit_ids, groups, derived_booking_times_start,derived_booking_times_end = np.array(outfit_ids), np.array(groups), np.array(derived_booking_times_start),np.array(derived_booking_times_end)\n",
    "    num_to_leave = max(math.floor(len(outfit_ids) * percentage), 1)\n",
    "\n",
    "    sorted_indices = np.argsort(derived_booking_times_start)\n",
    "    sorted_outfit_ids = outfit_ids[sorted_indices]\n",
    "    sorted_groups = groups[sorted_indices]\n",
    "    sorted_booking_times_start = derived_booking_times_start[sorted_indices]\n",
    "    sorted_booking_times_end = derived_booking_times_end[sorted_indices]\n",
    "    \n",
    "    unique_groups, counts = np.unique(sorted_groups, return_counts=True)\n",
    "    \n",
    "    single_count_indices = np.where(counts == 1)[0]\n",
    "    if len(single_count_indices) == 0:\n",
    "        print(f\"No unique outfit found with groups {groups}\")\n",
    "        return None\n",
    "    \n",
    "    # Find the actual indices in the sorted arrays where the unique groups are located\n",
    "    unique_group_mask = np.isin(sorted_groups, unique_groups[single_count_indices])\n",
    "    \n",
    "    # Indices of single count elements\n",
    "    single_count_actual_indices = np.where(unique_group_mask)[0]\n",
    "    \n",
    "    # Limit to the number to leave out based on the percentage\n",
    "    if len(single_count_actual_indices) > num_to_leave:\n",
    "        single_count_actual_indices = single_count_actual_indices[:num_to_leave]\n",
    "\n",
    "    # Remaining indices that are not in single_count_actual_indices\n",
    "    remaining_indices = np.setdiff1d(np.arange(len(sorted_groups)), single_count_actual_indices)\n",
    "    \n",
    "    return (\n",
    "    outfit_ids[sorted_indices[:-num_to_leave]], outfit_ids[sorted_indices[-num_to_leave:]], \n",
    "        groups[sorted_indices[:-num_to_leave]], groups[sorted_indices[-num_to_leave:]], \n",
    "        derived_booking_times_start[sorted_indices[:-num_to_leave]], derived_booking_times_start[sorted_indices[-num_to_leave:]], \n",
    "        derived_booking_times_end[sorted_indices[:-num_to_leave]], derived_booking_times_end[sorted_indices[-num_to_leave:]]\n",
    "\n",
    "    )\n",
    "\n",
    "\n",
    "def convert_user_orders_to_train_test_splits(user_orders_df, date_column_start=\"rentalPeriod.start\", date_column_end=\"rentalPeriod.end\", percentage_test=None):\n",
    "    \"\"\"\n",
    "    Converts user orders DataFrame to training and test splits.\n",
    "\n",
    "    Parameters:\n",
    "    user_orders_df (DataFrame): DataFrame containing user orders.\n",
    "    date_column (str): Column name for booking times.\n",
    "    percentage_test (float, optional): Percentage of data to leave out for the test set.\n",
    "\n",
    "    Returns:\n",
    "    tuple: DataFrames for training and test splits.\n",
    "    \"\"\"\n",
    "    if percentage_test is not None:\n",
    "        user_splits = user_orders_df.apply(lambda x: leave_percentage_out_split(x[\"outfit.id\"], x[\"group\"], x[date_column_start], x[date_column_end], percentage=percentage_test), axis=1)\n",
    "    else:\n",
    "        user_splits = user_orders_df.apply(lambda x: leave_one_out_split(x[\"outfit.id\"], x[\"group\"], x[date_column_start], x[date_column_end]), axis=1)\n",
    "    \n",
    "    user_splits_df = pd.DataFrame(user_splits.tolist(), columns=[\"train_outfit_ids\", \"test_outfit_id\", \"train_group\", \"test_group\", \"train_booking_times_start\", \"test_booking_time_start\", \"train_booking_times_end\", \"test_booking_time_end\"])\n",
    "    \n",
    "    if percentage_test is not None:\n",
    "        user_splits_unique = user_orders_df.apply(lambda x: leave_percentage_out_split_unique(x[\"outfit.id\"], x[\"group\"], x[date_column_start], x[date_column_end], percentage=percentage_test), axis=1)\n",
    "    else:\n",
    "        user_splits_unique = user_orders_df.apply(lambda x: leave_one_out_split_unique(x[\"outfit.id\"], x[\"group\"], x[date_column_start], x[date_column_end]), axis=1)\n",
    "    \n",
    "    user_splits_unique_df = pd.DataFrame(user_splits_unique.tolist(), columns=[\"train_outfit_ids\", \"test_outfit_id\", \"train_group\", \"test_group\", \"train_booking_times_start\", \"test_booking_time_start\", \"train_booking_times_end\", \"test_booking_time_end\"])\n",
    "    user_splits_unique_df = user_splits_unique_df.dropna()\n",
    "    \n",
    "    return user_splits_df, user_splits_unique_df\n",
    "\n",
    "# Some entries among the triplet data have been rented twice for within short time intervals. Often, these are mistaken entries and should be removed.\n",
    "# Other times the outfit has been rented for two consecutive months, regardless we should remove these entries.\n",
    "def remove_consecutive_duplicates(user_triplets_df, date_column=\"rentalPeriod.start\"):\n",
    "    \"\"\"\n",
    "    Removes consecutive duplicate entries from the DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "    user_triplets_df (DataFrame): DataFrame containing user triplets.\n",
    "    date_column (str): Column name for booking times.\n",
    "\n",
    "    Returns:\n",
    "    DataFrame: DataFrame with consecutive duplicates removed.\n",
    "    \"\"\"\n",
    "    user_triplets_df[date_column] = pd.to_datetime(user_triplets_df[date_column])\n",
    "\n",
    "    drop_indexes = []\n",
    "    for i, (customer_id, group) in enumerate(user_triplets_df.groupby('customer.id')):\n",
    "        # Check if any repeated outfit ids have less than a month between booking times.\n",
    "        repeated_ids = group[\"outfit.id\"].value_counts() > 1\n",
    "        for repeated_id in repeated_ids[repeated_ids].index:\n",
    "            repeated_subset = group[group[\"outfit.id\"] == repeated_id]\n",
    "            previous_entry_index = 0 # Since we'll occasionally find more than two repeated entries, we need to keep track of the last valid index we have.\n",
    "            for i in range(1, repeated_subset.shape[0]):\n",
    "                if (repeated_subset.iloc[i][date_column] - repeated_subset.iloc[previous_entry_index][date_column]).days < 30:\n",
    "                    drop_indexes.append(repeated_subset.index[i])\n",
    "                else:\n",
    "                    previous_entry_index = i\n",
    "\n",
    "    print(len(drop_indexes))\n",
    "    user_triplets_df = user_triplets_df.drop(drop_indexes)    \n",
    "    return user_triplets_df\n",
    "\n",
    "# Convert the triplets format with one transaction per row to a format all transactions per user\n",
    "def translate_user_triplets_to_orders(user_triplets_df, outfits_df): \n",
    "    \"\"\"\n",
    "    Converts user triplets DataFrame to user orders DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "    user_triplets_df (DataFrame): DataFrame containing user triplets.\n",
    "    outfits_df (DataFrame): DataFrame containing outfit information.\n",
    "\n",
    "    Returns:\n",
    "    DataFrame: DataFrame with user orders.\n",
    "    \"\"\"\n",
    "    # Translate the outfit ids to outfit groups before aggregating\n",
    "    id_group_dict = outfits_df[[\"id\", \"group\"]].to_dict(orient=\"records\")\n",
    "    id_group_dict = {x[\"id\"]: x[\"group\"] for x in id_group_dict}\n",
    "\n",
    "    user_triplets_df[\"group\"] = user_triplets_df[\"outfit.id\"].map(id_group_dict)\n",
    "    #display(user_triplets_df)\n",
    "\n",
    "    # Aggregate the outfit ids, groups, validFrom and bookingTime for each user\n",
    "    user_orders_df = user_triplets_df.groupby(\"customer.id\").agg({\"outfit.id\": list, \"group\":list, \"rentalPeriod.start\":list, \"rentalPeriod.end\":list}).reset_index()\n",
    "    user_orders_df[\"num_orders\"] = user_orders_df[\"outfit.id\"].apply(lambda x: len(x))\n",
    "    user_orders_df = user_orders_df[user_orders_df[\"num_orders\"] > 1]\n",
    "    return user_orders_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56ed9ef7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
