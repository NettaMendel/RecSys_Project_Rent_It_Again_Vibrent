{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fe26a214-df69-4cc9-a97e-6e9f6553c118",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: implicit in c:\\users\\user\\anaconda3\\lib\\site-packages (0.7.2)\n",
      "Requirement already satisfied: scipy>=0.16 in c:\\users\\user\\anaconda3\\lib\\site-packages (from implicit) (1.9.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\user\\anaconda3\\lib\\site-packages (from implicit) (4.64.1)\n",
      "Requirement already satisfied: numpy>=1.17.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from implicit) (1.21.5)\n",
      "Requirement already satisfied: threadpoolctl in c:\\users\\user\\anaconda3\\lib\\site-packages (from implicit) (2.2.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\user\\anaconda3\\lib\\site-packages (from tqdm>=4.27->implicit) (0.4.5)\n",
      "Requirement already satisfied: pyarrow in c:\\users\\user\\anaconda3\\lib\\site-packages (18.1.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install implicit\n",
    "#!pip install surprise\n",
    "!pip install pyarrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f14f64ac-caa6-402f-9077-8869c1a1c4ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import\n",
    "#warning\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#general\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from itertools import product\n",
    "\n",
    "#for predictions\n",
    "import implicit\n",
    "from implicit.bpr import BayesianPersonalizedRanking\n",
    "from implicit.lmf import LogisticMatrixFactorization\n",
    "from implicit.nearest_neighbours import ItemItemRecommender, BM25Recommender\n",
    "from scipy.sparse import coo_matrix\n",
    "\n",
    "%run prepare_train_test_splits.ipynb\n",
    "%run evaluate_models.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "767e6793-3268-44ce-97e1-b7ecb432013e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data\n",
    "orders=pd.read_parquet('../archive/data/orders.parquet',engine='pyarrow')\n",
    "outfits=pd.read_parquet('../archive/data/outfits.parquet',engine='pyarrow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f53dc873",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3607\n",
      "No unique outfit found with groups ['group.423a23f6717e6d85adac54c051ee9832'\n",
      " 'group.423a23f6717e6d85adac54c051ee9832']\n",
      "No unique outfit found with groups ['group.384b8170c6a6ddfd568ff7fab5fb49c4'\n",
      " 'group.384b8170c6a6ddfd568ff7fab5fb49c4']\n",
      "No unique outfit found with groups ['group.a3ab26b5d2f7ef2cf102422a3dde3b46'\n",
      " 'group.a3ab26b5d2f7ef2cf102422a3dde3b46']\n",
      "No unique outfit found with groups ['group.9b5204b87abc93f8f0467b0a6a9c6a97'\n",
      " 'group.9b5204b87abc93f8f0467b0a6a9c6a97'\n",
      " 'group.9b5204b87abc93f8f0467b0a6a9c6a97']\n",
      "No unique outfit found with groups ['group.8e50238120d13b31284f151941c2ee81'\n",
      " 'group.8e50238120d13b31284f151941c2ee81']\n",
      "No unique outfit found with groups ['group.a494d07781a1aab0e3a42989288feff2'\n",
      " 'group.a494d07781a1aab0e3a42989288feff2']\n",
      "No unique outfit found with groups ['group.a1d284ef1c7035dd14e57eba3838a303'\n",
      " 'group.a1d284ef1c7035dd14e57eba3838a303']\n",
      "No unique outfit found with groups ['group.e0cb0f6e113edc4df8a1e304376734f6'\n",
      " 'group.e0cb0f6e113edc4df8a1e304376734f6']\n",
      "No unique outfit found with groups ['group.2c7095c075561fe6278f3a2d7c1d6ac9'\n",
      " 'group.2c7095c075561fe6278f3a2d7c1d6ac9']\n",
      "No unique outfit found with groups ['group.ae8da3f0ad6f8ff3f83b2af96e975991'\n",
      " 'group.ae8da3f0ad6f8ff3f83b2af96e975991']\n",
      "No unique outfit found with groups ['group.4bd4ee24eac8948e82783b15d9404f6b'\n",
      " 'group.4bd4ee24eac8948e82783b15d9404f6b']\n",
      "No unique outfit found with groups ['group.1bfd2412df50ac58b23bd8f52c6b4b35'\n",
      " 'group.1bfd2412df50ac58b23bd8f52c6b4b35']\n",
      "No unique outfit found with groups ['group.edb60c2f440a9ac7d0883fb9371c8607'\n",
      " 'group.edb60c2f440a9ac7d0883fb9371c8607']\n"
     ]
    }
   ],
   "source": [
    "#prepare data\n",
    "\n",
    "#convert tag_categories and outfit_tags to lists\n",
    "outfits[\"tag_categories\"] = outfits[\"tag_categories\"].apply(eval)\n",
    "outfits[\"outfit_tags\"] = outfits[\"outfit_tags\"].apply(eval)\n",
    "\n",
    "outfits['group']=outfits['group'].astype(str)\n",
    "\n",
    "# Convert triplets into entries for each individual user\n",
    "orders = remove_consecutive_duplicates(orders)\n",
    "user_orders_df = translate_user_triplets_to_orders(orders, outfits)\n",
    "user_orders_df.dropna(inplace=True)\n",
    "\n",
    "# Split the data into train and test sets, with one dataframe with no restirictions on outfits in the test data and one that prohibits repeated outfits\n",
    "# It prints any cases in which it is unable to construct a test set with unique outfits.\n",
    "user_splits_df, user_splits_unique_df = convert_user_orders_to_train_test_splits(user_orders_df, percentage_test=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0bb7cc7",
   "metadata": {},
   "source": [
    "### ALS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9e5bf10f-9142-4cf0-8d3c-f848692d2dea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\anaconda3\\lib\\site-packages\\implicit\\cpu\\als.py:95: RuntimeWarning: Intel MKL BLAS is configured to use 4 threads. It is highly recommended to disable its internal threadpool by setting the environment variable 'MKL_NUM_THREADS=1' or by callng 'threadpoolctl.threadpool_limits(1, \"blas\")'. Having MKL use a threadpool can lead to severe performance issues\n",
      "  check_blas_config()\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa62b9e4164d4691993284e1b7cdd39c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34c9498575c743cfa460b64f69bd99ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run name: All Outfits Factors: 32, Regularization: 0.01\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "id_hit_rate_at_100       0.176395\n",
       "id_hit_rate_at_10        0.038740\n",
       "group_hit_rate_at_100    0.239411\n",
       "group_hit_rate_at_10     0.058884\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef94bb47285d49c49e692b009f61df16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a5a4a73c3de4f54998dbdf33b1907c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run name: Unique Outfit Factors: 32, Regularization: 0.01\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "id_hit_rate_at_100       0.156258\n",
       "id_hit_rate_at_10        0.036797\n",
       "group_hit_rate_at_100    0.222078\n",
       "group_hit_rate_at_10     0.062970\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================\n"
     ]
    }
   ],
   "source": [
    "def train_als_model(user_splits_df, outfit_column, factors=16, regularization=0.1, iterations=50):\n",
    "    flat_df = user_splits_df.explode(outfit_column)\n",
    "    flat_df[\"value\"] = 1\n",
    "    \n",
    "    unique_outfit_ids = flat_df[outfit_column].unique()\n",
    "    outfit_to_index = {outfit_id: i for i, outfit_id in enumerate(unique_outfit_ids)}\n",
    "    flat_df[\"outfit_index\"] = flat_df[outfit_column].map(outfit_to_index)\n",
    "    \n",
    "    unique_users = pd.unique(flat_df.index)\n",
    "    user_to_index = {user_id: i for i, user_id in enumerate(unique_users)}\n",
    "    flat_df['user_index'] = flat_df.index.map(user_to_index)\n",
    "    \n",
    "    # Debug: Check if there are any negative indices\n",
    "    if (flat_df['outfit_index'] < 0).any():\n",
    "        raise ValueError('Negative outfit_index found')\n",
    "    if (flat_df['user_index'] < 0).any():\n",
    "        raise ValueError('Negative user_index found')\n",
    "\n",
    "    coo = coo_matrix(\n",
    "        (flat_df['value'].values, (flat_df['user_index'].values, flat_df['outfit_index'].values)),\n",
    "        shape=(len(unique_users), len(unique_outfit_ids))\n",
    "    )\n",
    "    \n",
    "    np.random.seed(42)\n",
    "    model = implicit.als.AlternatingLeastSquares(factors=factors, regularization=regularization, iterations=iterations, )\n",
    "    csr = coo.tocsr()\n",
    "    model.fit(csr)\n",
    "\n",
    "    return model, csr, outfit_to_index, user_to_index\n",
    "\n",
    "def run_als_training_loop(df, factors, regularization, run_name=\"\"):\n",
    "    model_ind, csr_ind, outfit_id_to_index, user_to_index = train_als_model(df, \"train_outfit_ids\", factors=factors, regularization=regularization)\n",
    "    model_group, csr_group, outfit_group_to_index, _ = train_als_model(df, \"train_group\", factors=factors, regularization=regularization)\n",
    "\n",
    "    df[\"user_index\"] = df.index.map(user_to_index)\n",
    "\n",
    "    ind_index_to_id = {value : key for key, value in outfit_id_to_index.items()}\n",
    "    df[\"ind_recommendations\"] = df.apply(lambda x: evaluate_model(model_ind, csr_ind, x[\"user_index\"], n=100), axis=1)\n",
    "    df[\"ind_recommendations\"] = df.apply(lambda x: get_outfit_id_from_index(x[\"ind_recommendations\"], ind_index_to_id), axis=1)\n",
    "\n",
    "    group_index_to_id = {value : key for key, value in outfit_group_to_index.items()}\n",
    "    df[\"group_recommendations\"] = df.apply(lambda x: evaluate_model(model_group, csr_group, x[\"user_index\"], n=100), axis=1)\n",
    "    df[\"group_recommendations\"] = df.apply(lambda x: get_outfit_id_from_index(x[\"group_recommendations\"], group_index_to_id), axis=1)\n",
    "\n",
    "    HIT_RATE_COLUMNS = [\"id_hit_rate_at_100\", \"id_hit_rate_at_10\", \"group_hit_rate_at_100\", \"group_hit_rate_at_10\"]\n",
    "    df[\"id_hit_rate_at_100\"] = df.apply(lambda x: evaluate_hit_rate_at_n(x[\"test_outfit_id\"], x[\"ind_recommendations\"], n=100), axis=1)\n",
    "    df[\"id_hit_rate_at_10\"] = df.apply(lambda x: evaluate_hit_rate_at_n(x[\"test_outfit_id\"], x[\"ind_recommendations\"], n=10), axis=1)\n",
    "    df[\"group_hit_rate_at_100\"] = df.apply(lambda x: evaluate_hit_rate_at_n(x[\"test_group\"], x[\"group_recommendations\"], n=100), axis=1)\n",
    "    df[\"group_hit_rate_at_10\"] = df.apply(lambda x: evaluate_hit_rate_at_n(x[\"test_group\"], x[\"group_recommendations\"], n=10), axis=1)\n",
    "\n",
    "    print(f\"Run name: {run_name} Factors: {factors}, Regularization: {regularization}\")\n",
    "    display(df[HIT_RATE_COLUMNS].mean())\n",
    "    print(\"=\"*20)\n",
    "\n",
    "    result_dict = {column: df[column].mean() for column in HIT_RATE_COLUMNS}\n",
    "\n",
    "    return df, (factors, regularization, df[\"group_hit_rate_at_100\"].mean(), run_name), result_dict\n",
    "    \n",
    "\n",
    "\n",
    "TEST_FACTORS = [32]\n",
    "TEST_REGULARIZATIONS = [0.01]\n",
    "run_dataframes = [(user_splits_df, \"All Outfits\"), (user_splits_unique_df, \"Unique Outfit\")]\n",
    "\n",
    "test_permutations = list(product(TEST_FACTORS, TEST_REGULARIZATIONS))\n",
    "test_permutations = [(t_factors, t_reg, run_df) for t_factors, t_reg, run_df in product(TEST_FACTORS, TEST_REGULARIZATIONS, run_dataframes)]\n",
    "\n",
    "group_hr_10_means, result_dicts = [], []\n",
    "for test_factors, test_regularization, (df, run_name) in test_permutations:\n",
    "    df, result, result_dict = run_als_training_loop(df, test_factors, test_regularization, run_name=run_name)\n",
    "    result_dicts.append(result_dict)\n",
    "    group_hr_10_means.append(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbd4aacc",
   "metadata": {},
   "source": [
    "### BPR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "618af0d2-d220-469b-bb4d-d841d0487acc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30711949063a47f1911a72e401464b06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c958299784814c1e95c1675128bb8801",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run name: All Outfits Factors: 128, Regularization: 0.01\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "id_hit_rate_at_100       0.200671\n",
       "id_hit_rate_at_10        0.033316\n",
       "group_hit_rate_at_100    0.227014\n",
       "group_hit_rate_at_10     0.045196\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58588a1bfaaf4b10950e1b14dce8f3a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95744f6bcfe44fffb40ef8a6b0c1ef59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run name: Unique Outfit Factors: 128, Regularization: 0.01\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "id_hit_rate_at_100       0.217932\n",
       "id_hit_rate_at_10        0.039907\n",
       "group_hit_rate_at_100    0.243068\n",
       "group_hit_rate_at_10     0.051049\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================\n"
     ]
    }
   ],
   "source": [
    "def train_bpr_model(user_splits_df, outfit_column, factors=16, regularization=0.1, learning_rate=0.1, iterations=500):\n",
    "    flat_df = user_splits_df.explode(outfit_column)\n",
    "    flat_df[\"value\"] = 1\n",
    "    \n",
    "    unique_outfit_ids = flat_df[outfit_column].unique()\n",
    "    outfit_to_index = {outfit_id: i for i, outfit_id in enumerate(unique_outfit_ids)}\n",
    "    flat_df[\"outfit_index\"] = flat_df[outfit_column].map(outfit_to_index)\n",
    "    \n",
    "    unique_users = pd.unique(flat_df.index)\n",
    "    user_to_index = {user_id: i for i, user_id in enumerate(unique_users)}\n",
    "    flat_df['user_index'] = flat_df.index.map(user_to_index)\n",
    "    \n",
    "    # Debug: Check if there are any negative indices\n",
    "    if (flat_df['outfit_index'] < 0).any():\n",
    "        raise ValueError('Negative outfit_index found')\n",
    "    if (flat_df['user_index'] < 0).any():\n",
    "        raise ValueError('Negative user_index found')\n",
    "\n",
    "    coo = coo_matrix(\n",
    "        (flat_df['value'].values, (flat_df['user_index'].values, flat_df['outfit_index'].values)),\n",
    "        shape=(len(unique_users), len(unique_outfit_ids))\n",
    "    )\n",
    "    \n",
    "    np.random.seed(43)\n",
    "    model = BayesianPersonalizedRanking(factors=factors, regularization=regularization, iterations=iterations, learning_rate=learning_rate)\n",
    "    csr = coo.tocsr()\n",
    "    model.fit(csr)\n",
    "    \n",
    "    return model, csr, outfit_to_index, user_to_index\n",
    "\n",
    "\n",
    "def run_bpr_training_loop(df, factors, regularization, learning_rate, run_name=\"\"):\n",
    "    model_ind, csr_ind, outfit_id_to_index, user_to_index = train_bpr_model(df, \"train_outfit_ids\", factors=factors, regularization=regularization, learning_rate=learning_rate)\n",
    "    model_group, csr_group, outfit_group_to_index, _ = train_bpr_model(df, \"train_group\", factors=factors, regularization=regularization, learning_rate=learning_rate)\n",
    "\n",
    "    df[\"user_index\"] = df.index.map(user_to_index)\n",
    "\n",
    "    ind_index_to_id = {value : key for key, value in outfit_id_to_index.items()}\n",
    "    df[\"ind_recommendations\"] = df.apply(lambda x: evaluate_model(model_ind, csr_ind, x[\"user_index\"], n=100), axis=1)\n",
    "    df[\"ind_recommendations\"] = df.apply(lambda x: get_outfit_id_from_index(x[\"ind_recommendations\"], ind_index_to_id), axis=1)\n",
    "\n",
    "    group_index_to_id = {value : key for key, value in outfit_group_to_index.items()}\n",
    "    df[\"group_recommendations\"] = df.apply(lambda x: evaluate_model(model_group, csr_group, x[\"user_index\"], n=100), axis=1)\n",
    "    df[\"group_recommendations\"] = df.apply(lambda x: get_outfit_id_from_index(x[\"group_recommendations\"], group_index_to_id), axis=1)\n",
    "\n",
    "    HIT_RATE_COLUMNS = [\"id_hit_rate_at_100\", \"id_hit_rate_at_10\", \"group_hit_rate_at_100\", \"group_hit_rate_at_10\"]\n",
    "    df[\"id_hit_rate_at_100\"] = df.apply(lambda x: evaluate_hit_rate_at_n(x[\"test_outfit_id\"], x[\"ind_recommendations\"], n=100), axis=1)\n",
    "    df[\"id_hit_rate_at_10\"] = df.apply(lambda x: evaluate_hit_rate_at_n(x[\"test_outfit_id\"], x[\"ind_recommendations\"], n=10), axis=1)\n",
    "    df[\"group_hit_rate_at_100\"] = df.apply(lambda x: evaluate_hit_rate_at_n(x[\"test_group\"], x[\"group_recommendations\"], n=100), axis=1)\n",
    "    df[\"group_hit_rate_at_10\"] = df.apply(lambda x: evaluate_hit_rate_at_n(x[\"test_group\"], x[\"group_recommendations\"], n=10), axis=1)\n",
    "\n",
    "    print(f\"Run name: {run_name} Factors: {factors}, Regularization: {regularization}\")\n",
    "    display(df[HIT_RATE_COLUMNS].mean())\n",
    "    print(\"=\"*20)\n",
    "\n",
    "    result_dict = {column: df[column].mean() for column in HIT_RATE_COLUMNS}\n",
    "\n",
    "    return df, (factors, regularization, df[\"group_hit_rate_at_100\"].mean(), df[\"id_hit_rate_at_100\"].mean(), run_name), result_dict\n",
    "\n",
    "\n",
    "TEST_FACTORS = [128]\n",
    "TEST_REGULARIZATIONS = [0.01]\n",
    "TEST_LEARNING_RATES = [0.01]\n",
    "run_dataframes = [(user_splits_df, \"All Outfits\"), (user_splits_unique_df, \"Unique Outfit\")]\n",
    "\n",
    "test_permutations = list(product(TEST_FACTORS, TEST_REGULARIZATIONS, TEST_LEARNING_RATES))\n",
    "test_permutations = [(t_factors, t_reg, t_lr, run_df) for t_factors, t_reg, t_lr, run_df in product(TEST_FACTORS, TEST_REGULARIZATIONS, TEST_LEARNING_RATES, run_dataframes)]\n",
    "\n",
    "group_hr_10_means, result_dicts, result_dataframes = [], [], []\n",
    "for test_factors, test_regularization, test_learning_rate, (df, run_name) in test_permutations:\n",
    "    df, result, result_dict = run_bpr_training_loop(df, test_factors, test_regularization, test_learning_rate, run_name=run_name)\n",
    "    result_dicts.append(result_dict)\n",
    "    group_hr_10_means.append(result)\n",
    "    result_dataframes.append(df.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a4028fac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.20067148760330578 0.2179321067634102\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.08548553719008264"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check whether the exact hit items for individual and group recommendations overlap for BPR\n",
    "\n",
    "standard_result_df, unique_result_df = result_dataframes\n",
    "print(standard_result_df[\"id_hit_rate_at_100\"].mean(), unique_result_df[\"id_hit_rate_at_100\"].mean())\n",
    "\n",
    "unique_columns = [\"u_\" + column_name for column_name in unique_result_df.columns]\n",
    "unique_result_df.columns = unique_columns\n",
    "\n",
    "def check_if_overlap_in_hit(row, column_name):\n",
    "    hit_standard = row[column_name]\n",
    "    hit_unique = row[\"u_\" + column_name]\n",
    "    return hit_standard > 0.1 and hit_unique > 0.1\n",
    "\n",
    "all_results = pd.concat([standard_result_df, unique_result_df], axis=1)\n",
    "all_results[\"overlap_100\"] = all_results.apply(lambda x: check_if_overlap_in_hit(x, \"id_hit_rate_at_100\"), axis=1)\n",
    "all_results[\"overlap_100\"].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "276ec095",
   "metadata": {},
   "source": [
    "### MF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a89935fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "978a537689b74bba82b608b4083da263",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00b816000c134a9eb71d608e900bb5e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run name: All Outfits Factors: 128, Regularization: 0.01\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "id_hit_rate_at_100       0.036415\n",
       "id_hit_rate_at_10        0.004132\n",
       "group_hit_rate_at_100    0.052686\n",
       "group_hit_rate_at_10     0.005424\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e96be85965245439347b3e4cad2296b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a10ac42adb84617bca550a0eae46033",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run name: Unique Outfit Factors: 128, Regularization: 0.01\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "id_hit_rate_at_100       0.037315\n",
       "id_hit_rate_at_10        0.005442\n",
       "group_hit_rate_at_100    0.053900\n",
       "group_hit_rate_at_10     0.004924\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================\n"
     ]
    }
   ],
   "source": [
    "def train_lmf_model(user_splits_df, outfit_column, factors=16, regularization=0.1, learning_rate=0.1, iterations=500):\n",
    "    flat_df = user_splits_df.explode(outfit_column)\n",
    "    flat_df[\"value\"] = 1\n",
    "    \n",
    "    unique_outfit_ids = flat_df[outfit_column].unique()\n",
    "    outfit_to_index = {outfit_id: i for i, outfit_id in enumerate(unique_outfit_ids)}\n",
    "    flat_df[\"outfit_index\"] = flat_df[outfit_column].map(outfit_to_index)\n",
    "    \n",
    "    unique_users = pd.unique(flat_df.index)\n",
    "    user_to_index = {user_id: i for i, user_id in enumerate(unique_users)}\n",
    "    flat_df['user_index'] = flat_df.index.map(user_to_index)\n",
    "    \n",
    "    # Debug: Check if there are any negative indices\n",
    "    if (flat_df['outfit_index'] < 0).any():\n",
    "        raise ValueError('Negative outfit_index found')\n",
    "    if (flat_df['user_index'] < 0).any():\n",
    "        raise ValueError('Negative user_index found')\n",
    "\n",
    "    coo = coo_matrix(\n",
    "        (flat_df['value'].values, (flat_df['user_index'].values, flat_df['outfit_index'].values)),\n",
    "        shape=(len(unique_users), len(unique_outfit_ids))\n",
    "    )\n",
    "    \n",
    "    np.random.seed(43)\n",
    "    model = LogisticMatrixFactorization(factors=factors, regularization=regularization, iterations=iterations, learning_rate=learning_rate)\n",
    "    csr = coo.tocsr()\n",
    "    model.fit(csr)\n",
    "    \n",
    "    return model, csr, outfit_to_index, user_to_index\n",
    "\n",
    "def run_lmf_training_loop(df, factors, regularization, learning_rate, run_name=\"\"):\n",
    "    model_ind, csr_ind, outfit_id_to_index, user_to_index = train_lmf_model(df, \"train_outfit_ids\", factors=factors, regularization=regularization, learning_rate=learning_rate)\n",
    "    model_group, csr_group, outfit_group_to_index, _ = train_lmf_model(df, \"train_group\", factors=factors, regularization=regularization, learning_rate=learning_rate)\n",
    "\n",
    "    df[\"user_index\"] = df.index.map(user_to_index)\n",
    "\n",
    "    ind_index_to_id = {value : key for key, value in outfit_id_to_index.items()}\n",
    "    df[\"ind_recommendations\"] = df.apply(lambda x: evaluate_model(model_ind, csr_ind, x[\"user_index\"], n=100), axis=1)\n",
    "    df[\"ind_recommendations\"] = df.apply(lambda x: get_outfit_id_from_index(x[\"ind_recommendations\"], ind_index_to_id), axis=1)\n",
    "\n",
    "    group_index_to_id = {value : key for key, value in outfit_group_to_index.items()}\n",
    "    df[\"group_recommendations\"] = df.apply(lambda x: evaluate_model(model_group, csr_group, x[\"user_index\"], n=100), axis=1)\n",
    "    df[\"group_recommendations\"] = df.apply(lambda x: get_outfit_id_from_index(x[\"group_recommendations\"], group_index_to_id), axis=1)\n",
    "\n",
    "    HIT_RATE_COLUMNS = [\"id_hit_rate_at_100\", \"id_hit_rate_at_10\", \"group_hit_rate_at_100\", \"group_hit_rate_at_10\"]\n",
    "    df[\"id_hit_rate_at_100\"] = df.apply(lambda x: evaluate_hit_rate_at_n(x[\"test_outfit_id\"], x[\"ind_recommendations\"], n=100), axis=1)\n",
    "    df[\"id_hit_rate_at_10\"] = df.apply(lambda x: evaluate_hit_rate_at_n(x[\"test_outfit_id\"], x[\"ind_recommendations\"], n=10), axis=1)\n",
    "    df[\"group_hit_rate_at_100\"] = df.apply(lambda x: evaluate_hit_rate_at_n(x[\"test_group\"], x[\"group_recommendations\"], n=100), axis=1)\n",
    "    df[\"group_hit_rate_at_10\"] = df.apply(lambda x: evaluate_hit_rate_at_n(x[\"test_group\"], x[\"group_recommendations\"], n=10), axis=1)\n",
    "\n",
    "    print(f\"Run name: {run_name} Factors: {factors}, Regularization: {regularization}\")\n",
    "    display(df[HIT_RATE_COLUMNS].mean())\n",
    "    print(\"=\"*20)\n",
    "\n",
    "    result_dict = {column: df[column].mean() for column in HIT_RATE_COLUMNS}\n",
    "\n",
    "    return df, (factors, regularization, df[\"group_hit_rate_at_10\"].mean(), df[\"id_hit_rate_at_10\"].mean(), run_name), result_dict\n",
    "\n",
    "\n",
    "TEST_FACTORS = [128]\n",
    "TEST_REGULARIZATIONS = [0.01]\n",
    "TEST_LEARNING_RATES = [0.01]\n",
    "#run_dataframes = [user_splits_df]\n",
    "run_dataframes = [(user_splits_df, \"All Outfits\"), (user_splits_unique_df, \"Unique Outfit\")]\n",
    "\n",
    "test_permutations = list(product(TEST_FACTORS, TEST_REGULARIZATIONS, TEST_LEARNING_RATES))\n",
    "test_permutations = [(t_factors, t_reg, t_lr, run_df) for t_factors, t_reg, t_lr, run_df in product(TEST_FACTORS, TEST_REGULARIZATIONS, TEST_LEARNING_RATES, run_dataframes)]\n",
    "\n",
    "group_hr_10_means, result_dicts = [], []\n",
    "for test_factors, test_regularization, test_learning_rate, (df, run_name) in test_permutations:\n",
    "    df, result, result_dict = run_lmf_training_loop(df, test_factors, test_regularization, test_learning_rate, run_name=run_name)\n",
    "    result_dicts.append(result_dict)\n",
    "    group_hr_10_means.append(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cf22bf0",
   "metadata": {},
   "source": [
    "### NN\n",
    "not in the original code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3c569204",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52b8902131cd429294a804d01049688c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10791 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ad550a73f4747c38d8281d0c1bdfbda",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7236 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run name: All Outfits, K: 20\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "id_hit_rate_at_100       0.151085\n",
       "id_hit_rate_at_10        0.029184\n",
       "group_hit_rate_at_100    0.205062\n",
       "group_hit_rate_at_10     0.051653\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b595cdf8aada4cac9bf029757f87a113",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11151 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a01d3a77d9544f8fa3f8430a7d6fed8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7217 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run name: Unique Outfit, K: 20\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "id_hit_rate_at_100       0.127753\n",
       "id_hit_rate_at_10        0.028764\n",
       "group_hit_rate_at_100    0.188132\n",
       "group_hit_rate_at_10     0.059342\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================\n"
     ]
    }
   ],
   "source": [
    "def train_nn_model(user_splits_df, outfit_column, k=20):\n",
    "    flat_df = user_splits_df.explode(outfit_column)\n",
    "    flat_df[\"value\"] = 1\n",
    "    \n",
    "    unique_outfit_ids = flat_df[outfit_column].unique()\n",
    "    outfit_to_index = {outfit_id: i for i, outfit_id in enumerate(unique_outfit_ids)}\n",
    "    flat_df[\"outfit_index\"] = flat_df[outfit_column].map(outfit_to_index)\n",
    "    \n",
    "    unique_users = pd.unique(flat_df.index)\n",
    "    user_to_index = {user_id: i for i, user_id in enumerate(unique_users)}\n",
    "    flat_df['user_index'] = flat_df.index.map(user_to_index)\n",
    "    \n",
    "    # Debug: Check if there are any negative indices\n",
    "    if (flat_df['outfit_index'] < 0).any():\n",
    "        raise ValueError('Negative outfit_index found')\n",
    "    if (flat_df['user_index'] < 0).any():\n",
    "        raise ValueError('Negative user_index found')\n",
    "\n",
    "    coo = coo_matrix(\n",
    "    (flat_df['value'].astype(np.float64).values, (flat_df['user_index'].values, flat_df['outfit_index'].values)),\n",
    "    shape=(len(unique_users), len(unique_outfit_ids))\n",
    "    )\n",
    "    \n",
    "    np.random.seed(43)\n",
    "    model = ItemItemRecommender(K=k)\n",
    "    csr = coo.tocsr()\n",
    "    model.fit(csr)\n",
    "    \n",
    "    return model, csr, outfit_to_index, user_to_index\n",
    "\n",
    "def run_nn_training_loop(df, k, run_name=\"\"):\n",
    "    model_ind, csr_ind, outfit_id_to_index, user_to_index = train_nn_model(df, \"train_outfit_ids\", k)\n",
    "    model_group, csr_group, outfit_group_to_index, _ = train_nn_model(df, \"train_group\", k)\n",
    "\n",
    "    df[\"user_index\"] = df.index.map(user_to_index)\n",
    "\n",
    "    ind_index_to_id = {value : key for key, value in outfit_id_to_index.items()}\n",
    "    df[\"ind_recommendations\"] = df.apply(lambda x: evaluate_model(model_ind, csr_ind, x[\"user_index\"], n=100), axis=1)\n",
    "    df[\"ind_recommendations\"] = df.apply(lambda x: get_outfit_id_from_index(x[\"ind_recommendations\"], ind_index_to_id), axis=1)\n",
    "\n",
    "    group_index_to_id = {value : key for key, value in outfit_group_to_index.items()}\n",
    "    df[\"group_recommendations\"] = df.apply(lambda x: evaluate_model(model_group, csr_group, x[\"user_index\"], n=100), axis=1)\n",
    "    df[\"group_recommendations\"] = df.apply(lambda x: get_outfit_id_from_index(x[\"group_recommendations\"], group_index_to_id), axis=1)\n",
    "\n",
    "    HIT_RATE_COLUMNS = [\"id_hit_rate_at_100\", \"id_hit_rate_at_10\", \"group_hit_rate_at_100\", \"group_hit_rate_at_10\"]\n",
    "    df[\"id_hit_rate_at_100\"] = df.apply(lambda x: evaluate_hit_rate_at_n(x[\"test_outfit_id\"], x[\"ind_recommendations\"], n=100), axis=1)\n",
    "    df[\"id_hit_rate_at_10\"] = df.apply(lambda x: evaluate_hit_rate_at_n(x[\"test_outfit_id\"], x[\"ind_recommendations\"], n=10), axis=1)\n",
    "    df[\"group_hit_rate_at_100\"] = df.apply(lambda x: evaluate_hit_rate_at_n(x[\"test_group\"], x[\"group_recommendations\"], n=100), axis=1)\n",
    "    df[\"group_hit_rate_at_10\"] = df.apply(lambda x: evaluate_hit_rate_at_n(x[\"test_group\"], x[\"group_recommendations\"], n=10), axis=1)\n",
    "\n",
    "    print(f\"Run name: {run_name}, K: {k}\")\n",
    "    display(df[HIT_RATE_COLUMNS].mean())\n",
    "    print(\"=\"*20)\n",
    "\n",
    "    result_dict = {column: df[column].mean() for column in HIT_RATE_COLUMNS}\n",
    "\n",
    "    return df, (k, df[\"group_hit_rate_at_10\"].mean(), df[\"id_hit_rate_at_10\"].mean(), run_name), result_dict\n",
    "\n",
    "K=[20]\n",
    "run_dataframes = [(user_splits_df, \"All Outfits\"), (user_splits_unique_df, \"Unique Outfit\")]\n",
    "\n",
    "test_permutations = list(product(K))\n",
    "test_permutations = [(k, run_df) for k, run_df in product(K, run_dataframes)]\n",
    "\n",
    "group_hr_10_means, result_dicts = [], []\n",
    "for k, (df, run_name) in test_permutations:\n",
    "    df, result, result_dict = run_nn_training_loop(df, k, run_name=run_name)\n",
    "    result_dicts.append(result_dict)\n",
    "    group_hr_10_means.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "55b149b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27120a13412d42a6a27ff4ef9c50a910",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10791 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97aad01b96fe40eabdf8bb0d0b99b8f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7236 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run name: All Outfits, K: 20, K1: 100, B: 0.8\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "id_hit_rate_at_100       0.079804\n",
       "id_hit_rate_at_10        0.010331\n",
       "group_hit_rate_at_100    0.089360\n",
       "group_hit_rate_at_10     0.016012\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13099b3396a3435b9c10d66ba7ec7996",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11151 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88cc77896ba543f28f05a4a3ff693b56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7217 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run name: Unique Outfit, K: 20, K1: 100, B: 0.8\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "id_hit_rate_at_100       0.072558\n",
       "id_hit_rate_at_10        0.013993\n",
       "group_hit_rate_at_100    0.084737\n",
       "group_hit_rate_at_10     0.016325\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================\n"
     ]
    }
   ],
   "source": [
    "def train_BM25_model(user_splits_df, outfit_column, k=20, k1=100, b=0.8):\n",
    "    flat_df = user_splits_df.explode(outfit_column)\n",
    "    flat_df[\"value\"] = 1\n",
    "    \n",
    "    unique_outfit_ids = flat_df[outfit_column].unique()\n",
    "    outfit_to_index = {outfit_id: i for i, outfit_id in enumerate(unique_outfit_ids)}\n",
    "    flat_df[\"outfit_index\"] = flat_df[outfit_column].map(outfit_to_index)\n",
    "    \n",
    "    unique_users = pd.unique(flat_df.index)\n",
    "    user_to_index = {user_id: i for i, user_id in enumerate(unique_users)}\n",
    "    flat_df['user_index'] = flat_df.index.map(user_to_index)\n",
    "    \n",
    "    # Debug: Check if there are any negative indices\n",
    "    if (flat_df['outfit_index'] < 0).any():\n",
    "        raise ValueError('Negative outfit_index found')\n",
    "    if (flat_df['user_index'] < 0).any():\n",
    "        raise ValueError('Negative user_index found')\n",
    "\n",
    "    coo = coo_matrix(\n",
    "    (flat_df['value'].astype(np.float64).values, (flat_df['user_index'].values, flat_df['outfit_index'].values)),\n",
    "    shape=(len(unique_users), len(unique_outfit_ids))\n",
    "    )\n",
    "    \n",
    "    np.random.seed(43)\n",
    "    model = BM25Recommender(K=k, K1=k1, B=b)\n",
    "    csr = coo.tocsr()\n",
    "    model.fit(csr)\n",
    "    \n",
    "    return model, csr, outfit_to_index, user_to_index\n",
    "\n",
    "def run_BM25_training_loop(df, k, k1, b, run_name=\"\"):\n",
    "    model_ind, csr_ind, outfit_id_to_index, user_to_index = train_BM25_model(df, \"train_outfit_ids\", k, k1, b)\n",
    "    model_group, csr_group, outfit_group_to_index, _ = train_BM25_model(df, \"train_group\", k, k1, b)\n",
    "\n",
    "    df[\"user_index\"] = df.index.map(user_to_index)\n",
    "\n",
    "    ind_index_to_id = {value : key for key, value in outfit_id_to_index.items()}\n",
    "    df[\"ind_recommendations\"] = df.apply(lambda x: evaluate_model(model_ind, csr_ind, x[\"user_index\"], n=100), axis=1)\n",
    "    df[\"ind_recommendations\"] = df.apply(lambda x: get_outfit_id_from_index(x[\"ind_recommendations\"], ind_index_to_id), axis=1)\n",
    "\n",
    "    group_index_to_id = {value : key for key, value in outfit_group_to_index.items()}\n",
    "    df[\"group_recommendations\"] = df.apply(lambda x: evaluate_model(model_group, csr_group, x[\"user_index\"], n=100), axis=1)\n",
    "    df[\"group_recommendations\"] = df.apply(lambda x: get_outfit_id_from_index(x[\"group_recommendations\"], group_index_to_id), axis=1)\n",
    "\n",
    "    HIT_RATE_COLUMNS = [\"id_hit_rate_at_100\", \"id_hit_rate_at_10\", \"group_hit_rate_at_100\", \"group_hit_rate_at_10\"]\n",
    "    df[\"id_hit_rate_at_100\"] = df.apply(lambda x: evaluate_hit_rate_at_n(x[\"test_outfit_id\"], x[\"ind_recommendations\"], n=100), axis=1)\n",
    "    df[\"id_hit_rate_at_10\"] = df.apply(lambda x: evaluate_hit_rate_at_n(x[\"test_outfit_id\"], x[\"ind_recommendations\"], n=10), axis=1)\n",
    "    df[\"group_hit_rate_at_100\"] = df.apply(lambda x: evaluate_hit_rate_at_n(x[\"test_group\"], x[\"group_recommendations\"], n=100), axis=1)\n",
    "    df[\"group_hit_rate_at_10\"] = df.apply(lambda x: evaluate_hit_rate_at_n(x[\"test_group\"], x[\"group_recommendations\"], n=10), axis=1)\n",
    "\n",
    "    print(f\"Run name: {run_name}, K: {k}, K1: {k1}, B: {b}\")\n",
    "    display(df[HIT_RATE_COLUMNS].mean())\n",
    "    print(\"=\"*20)\n",
    "\n",
    "    result_dict = {column: df[column].mean() for column in HIT_RATE_COLUMNS}\n",
    "\n",
    "    return df, (k, k1, b, df[\"group_hit_rate_at_10\"].mean(), df[\"id_hit_rate_at_10\"].mean(), run_name), result_dict\n",
    "\n",
    "K=[20]\n",
    "K1=[100]\n",
    "B=[0.8]\n",
    "run_dataframes = [(user_splits_df, \"All Outfits\"), (user_splits_unique_df, \"Unique Outfit\")]\n",
    "\n",
    "test_permutations = list(product(K, K1, B))\n",
    "test_permutations = [(k, k1, b, run_df) for k, k1, b, run_df in product(K, K1, B, run_dataframes)]\n",
    "\n",
    "group_hr_10_means, result_dicts = [], []\n",
    "for k, k1, b, (df, run_name) in test_permutations:\n",
    "    df, result, result_dict = run_BM25_training_loop(df, k, k1, b, run_name=run_name)\n",
    "    result_dicts.append(result_dict)\n",
    "    group_hr_10_means.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ed772a5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
